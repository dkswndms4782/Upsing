{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc7ca10-48cd-4706-b31c-f58214e5e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import itertools\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from ast import literal_eval\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Input \n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e66b95f0-0aed-4add-90eb-b12628da6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_wav(data, sample_rate, start, end):\n",
    "    start *= sample_rate\n",
    "    end *= sample_rate\n",
    "    return data[int(start):int(end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "073ebef2-3a06-41ef-833b-f98f2635ca5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "sr = 44100\n",
    "path = \"C:/Users/Ahn/projects/upsing/copy_song_mr_removed/\"\n",
    "filenames = os.listdir(path)\n",
    "song = pd.read_csv(\"C:/Users/Ahn/projects/upsing/song.csv\",converters={\"sec\":literal_eval})\n",
    "audio, label = [], []\n",
    "for file in filenames:\n",
    "    data, rate = librosa.load(path + file, sr=sr)\n",
    "    for idx in song.loc[song['song_name'] == file[:-4]].index:\n",
    "        if song.loc[idx,'label'] == '두성' or song.loc[idx,'label'] == '발음' : \n",
    "            continue\n",
    "        label.append(song.loc[idx,'label'])\n",
    "        edited_data = split_wav(data, sr, song.loc[idx,'sec'][0], song.loc[idx,'sec'][1])\n",
    "        if len(edited_data) < 67571:\n",
    "            edited_data = np.append(edited_data,[0 for _ in range(67571 - len(edited_data))] )\n",
    "        elif len(edited_data) > 67571:\n",
    "            edited_data = edited_data[:67571]\n",
    "        audio.append(np.array(edited_data))\n",
    "audio, label = np.array(audio), np.array(label)\n",
    "    # df = pd.DataFrame({'audio' : audio, \"label\" : label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd086da7-cfa3-4eee-aa56-2fef32f5edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "train_audio, test_audio, train_label, test_label = train_test_split(audio, label, test_size = 0.33, random_state = 2023, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c1b6fe9-0a1c-4917-8f61-0a665a7069a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1539\n"
     ]
    }
   ],
   "source": [
    "print(len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32e61ecb-ecb8-4c7f-a12a-e205887e166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mel(audio, label, name, save = True):\n",
    "    with tf.device('/GPU:0'):\n",
    "      audio_melspectrogram = []\n",
    "      for x in audio :\n",
    "        ret = librosa.feature.melspectrogram(y = x, sr = 44100)\n",
    "        audio_melspectrogram.append(ret)\n",
    "\n",
    "      amp_db = []\n",
    "      for i in range(len(audio_melspectrogram)) :\n",
    "        amp = librosa.amplitude_to_db(np.abs(audio_melspectrogram[i])) ## np.abs?\n",
    "        amp_db.append(amp)\n",
    "\n",
    "      features = []\n",
    "      for i in range(len(amp_db)) :\n",
    "        features.append([amp_db[i], label[i]])\n",
    "    \n",
    "      if save:\n",
    "        save_pickle(features, f\"mel_{name}_data\")\n",
    "\n",
    "      return pd.DataFrame(features, columns = ['audio', 'label'])\n",
    "train_mel = make_mel(train_audio, train_label, name = \"nonaugmented_train\", save = False)\n",
    "test_mel = make_mel(test_audio, test_label, name = \"nonaugmented_test\", save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d71eddaa-07e2-4239-b452-c10dae4443f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "teq = [\"비브라토\", \"보컬프라이\", \"벨팅\"]\n",
    "voc = [\"믹스드보이스\", \"흉성\", \"가성\", \"비성\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39d099ea-ad7c-4421-9580-5f068218bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "def train_test(train_features, test_features, shuffle = True, wave_flag=False, labelEncoder = True):\n",
    "  x_train = np.array(train_features.audio.tolist())\n",
    "  y_train = np.array(train_features.label.tolist())\n",
    "  x_test = np.array(test_features.audio.tolist())\n",
    "  y_test = np.array(test_features.label.tolist())\n",
    "\n",
    "  if labelEncoder:\n",
    "    le = LabelEncoder()\n",
    "    y_train = to_categorical(le.fit_transform(y_train))\n",
    "    y_test = to_categorical(le.transform(y_test))\n",
    "    print(le.classes_)\n",
    "\n",
    "  \n",
    "  if shuffle: \n",
    "    tmp = list(zip(x_train, y_train))\n",
    "    random.shuffle(tmp)\n",
    "    x_train, y_train = zip(*tmp)\n",
    "\n",
    "    tmp1 = list(zip(x_test, y_test))\n",
    "    random.shuffle(tmp1)\n",
    "    x_test, y_test = zip(*tmp1)\n",
    "    x_train, y_train, x_test, y_test = np.array(x_train,dtype=np.float32), np.array(y_train,dtype=np.float32), np.array(x_test,dtype=np.float32), np.array(y_test,dtype=np.float32)\n",
    "  \n",
    "  if wave_flag:\n",
    "    print(x_train.shape)\n",
    "    x_train = tf.reshape(x_train.astype(float), [-1, x_train.shape[1], 1]) ### 확인\n",
    "    x_test = tf.reshape(x_test.astype(float), [-1,  x_train.shape[1], 1])\n",
    "    return x_train, y_train, x_test, y_test, le\n",
    "  \n",
    "  n_channels = 1\n",
    "\n",
    "  with tf.device('/gpu:0'):\n",
    "    x_train = tf.reshape(x_train, [-1, x_train.shape[1], x_train.shape[2], n_channels])\n",
    "    x_test = tf.reshape(x_test, [-1,  x_test.shape[1], x_test.shape[2], n_channels])\n",
    "\n",
    "\n",
    "  return x_train, y_train, x_test, y_test, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d23c849-d21a-4d53-b816-64586ed95fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가성' '믹스드보이스' '벨팅' '보컬프라이' '비브라토' '비성' '흉성']\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test, le = train_test(train_mel, test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd914299-9f47-4397-8b85-054ee44f00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (None, 127, 86, 16) \n",
    "def make_model(input):\n",
    "  model = keras.Sequential()\n",
    "\n",
    "  model.add(layers.Conv2D(input_shape=(input[0].shape[0], input[0].shape[1], 1), filters=16, kernel_size=(1,2), activation='relu'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.MaxPooling2D(pool_size=2))\n",
    "  model.add(layers.Dropout(0.3))\n",
    "\n",
    "  model.add(layers.Conv2D(kernel_size=(1,8), filters=32, activation='relu'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.MaxPooling2D(pool_size=2))\n",
    "  model.add(layers.Dropout(0.3))\n",
    "\n",
    "  model.add(layers.Conv2D(kernel_size=(2,1), filters=64, activation='relu')) # 64\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.MaxPooling2D(pool_size=3))\n",
    "  model.add(layers.Dropout(0.3))\n",
    "\n",
    "  model.add(layers.Conv2D(kernel_size=(8,1), filters=128, activation='relu')) # 128\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.MaxPooling2D(pool_size=2)) ##\n",
    "  model.add(layers.Dropout(0.3)) #3\n",
    "\n",
    "  # model.add(layers.GlobalAveragePooling2D())\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(units=64)) # 128\n",
    "  model.add(tf.keras.layers.Dense(units=22))\n",
    "  model.add(tf.keras.layers.Dense(units=7, activation='softmax'))\n",
    "\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "training_epochs = 100\n",
    "num_batch_size = 64\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19ea3b29-16c6-45b9-894e-4bb5a8d197a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 128, 131, 16)      48        \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128, 131, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 64, 65, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64, 65, 16)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 58, 32)        4128      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64, 58, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 32, 29, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32, 29, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 31, 29, 64)        4160      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 31, 29, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 10, 9, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 10, 9, 64)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 3, 9, 128)         65664     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 3, 9, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 1, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 22)                1430      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,383\n",
      "Trainable params: 108,903\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001F0CE8413A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001F0CE8413A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 3.4738 - accuracy: 0.2897WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001F09CF949D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001F09CF949D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 3.4680 - accuracy: 0.2904 - val_loss: 2.0886 - val_accuracy: 0.1884\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 2.6632 - accuracy: 0.4198 - val_loss: 1.8043 - val_accuracy: 0.2951\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 3s 137ms/step - loss: 2.4639 - accuracy: 0.4535 - val_loss: 1.7030 - val_accuracy: 0.3426\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 3s 136ms/step - loss: 2.3724 - accuracy: 0.4555 - val_loss: 1.6384 - val_accuracy: 0.4097\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 3s 136ms/step - loss: 2.2335 - accuracy: 0.4373 - val_loss: 1.5983 - val_accuracy: 0.4269\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 3s 136ms/step - loss: 2.1767 - accuracy: 0.4659 - val_loss: 1.5887 - val_accuracy: 0.4282\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 3s 137ms/step - loss: 2.0243 - accuracy: 0.4906 - val_loss: 1.5760 - val_accuracy: 0.4256\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 3s 136ms/step - loss: 1.9522 - accuracy: 0.4893 - val_loss: 1.5676 - val_accuracy: 0.4361\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 3s 137ms/step - loss: 1.8763 - accuracy: 0.4977 - val_loss: 1.5826 - val_accuracy: 0.4229\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 3s 136ms/step - loss: 1.8819 - accuracy: 0.4964 - val_loss: 1.5885 - val_accuracy: 0.4308\n",
      "Epoch 11/100\n",
      "23/25 [==========================>...] - ETA: 0s - loss: 1.8605 - accuracy: 0.4946"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5468\\2169577541.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mearly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/gpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtmp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_epochs\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test loss, test acc:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                         ):\n\u001b[0;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1651\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[1;32m--> 135\u001b[1;33m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 53\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tmp_model = make_model(x_train)\n",
    "tmp_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "with tf.device('/gpu:0'):\n",
    "    tmp_model.fit(x_train, y_train, batch_size = num_batch_size, epochs = training_epochs , validation_data = (x_test, y_test) , callbacks = [early])\n",
    "    results = tmp_model.evaluate(x_test, y_test, batch_size=64)\n",
    "    print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3fa95a3-b406-4349-8bc6-9a46fc20252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c9781-4859-45dc-b1eb-e7475ee221af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d341857-176f-4b52-b80a-e5b5ac398040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72edf02e-7acf-4e7e-bdab-7d15a74a5474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282dca2-0b2e-4f98-9dcf-c4cb4aaadc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b20a47-87af-4f50-9aee-b1b0ff3acbb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
